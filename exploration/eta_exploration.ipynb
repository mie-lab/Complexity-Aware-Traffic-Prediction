{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6536cd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Copyright 2022 Institute of Advanced Research in Artificial Intelligence (IARAI) GmbH.\n",
    "#  IARAI licenses this file to You under the Apache License, Version 2.0\n",
    "#  (the \"License\"); you may not use this file except in compliance with\n",
    "#  the License. You may obtain a copy of the License at\n",
    "#  http://www.apache.org/licenses/LICENSE-2.0\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "#  limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8f874da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Alternatevly, in order to make the module imports work properly set PYTHONPATH=$PWD before launching the notebook server from the repo root folder.\n",
    "sys.path.insert(0, os.path.abspath(\"../\"))  # noqa:E402"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6766e703",
   "metadata": {},
   "source": [
    "![t4c20logo](../t4c20logo.png)\n",
    "\n",
    "This notebook explores the supersegment ETA values and provides a simple baseline to generate a submission.\n",
    "The baseline logic uses the total volume of all inputs (loop counter values) in a 15 minute input frame to assign the frame to one of 10 classes (clustered intervals of volume). These 10 cluster classes can be seen as a signal of total traffic load in the city.\n",
    "The ETAs per supersegment are aggregated (median) in these 10 classes. The resulting map can then be used to lookup the ETAs for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc9c5d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import t4c22\n",
    "\n",
    "from t4c22.misc.t4c22_logging import t4c_apply_basic_logging_config\n",
    "from t4c22.t4c22_config import load_basedir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04e8ae41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7115c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t4c_apply_basic_logging_config(loglevel=\"DEBUG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7cb2d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BASEDIR from file, change to your data root.\n",
    "BASEDIR = load_basedir(fn=\"t4c22_config.json\", pkg=t4c22)\n",
    "\n",
    "# Use already generated snapshots of aggregated median ETAs.\n",
    "USE_ETA_BASELINE_SNAPSHOTS = False\n",
    "\n",
    "EXPERIMENT_NAME = 'exp_c10'\n",
    "NUM_VOLUME_CLUSTERS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a81d4c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'london': [(0, -46599.0, 932240.2999999999), (1, 932240.2999999999, 1554726.4), (2, 1554726.4, 2588921.9000000004), (3, 2588921.9000000004, 3921954.0), (4, 3921954.0, 4863117.5), (5, 4863117.5, 5771968.0), (6, 5771968.0, 6005322.7), (7, 6005322.7, 6232288.4), (8, 6232288.4, 6493853.5), (9, 6493853.5, 7806420.0)], 'madrid': [(0, 263688.0, 923316.4), (1, 923316.4, 1911206.0), (2, 1911206.0, 3344747.900000001), (3, 3344747.900000001, 4972842.2), (4, 4972842.2, 6422392.0), (5, 6422392.0, 7669201.8), (6, 7669201.8, 8975374.4), (7, 8975374.4, 9762011.8), (8, 9762011.8, 10563257.9), (9, 10563257.9, 12361861.0)], 'melbourne': [(0, 35418.79999999999, 344195.01666666666), (1, 344195.01666666666, 588418.9400000001), (2, 588418.9400000001, 1072442.9133333336), (3, 1072442.9133333336, 1817113.62), (4, 1817113.62, 2663038.05), (5, 2663038.05, 3292800.466666667), (6, 3292800.466666667, 3936777.729999998), (7, 3936777.729999998, 4662487.213333336), (8, 4662487.213333336, 5325993.843333334), (9, 5325993.843333334, 6885818.7)]}\n"
     ]
    }
   ],
   "source": [
    "def load_train_input(city):\n",
    "    train_input_frames = []\n",
    "    for train_input_file in sorted((BASEDIR / 'train' / city / 'input').glob('counters_*.parquet')):\n",
    "        train_input_frames.append(pandas.read_parquet(train_input_file))\n",
    "    print(f'Read {len(train_input_frames)} training input files for {city}')\n",
    "    train_input = pandas.concat(train_input_frames)\n",
    "    train_input['vol'] = np.array(train_input['volumes_1h'].to_numpy().tolist()).sum(axis=1)\n",
    "    return train_input\n",
    "\n",
    "\n",
    "def load_train_labels(city):\n",
    "    train_label_frames = []\n",
    "    for train_label_file in sorted((BASEDIR / 'train' / city / 'labels').glob('eta_labels_*.parquet')):\n",
    "        train_label_frames.append(pandas.read_parquet(train_label_file))\n",
    "    print(f'Read {len(train_label_frames)} training label files')\n",
    "    train_labels = pandas.concat(train_label_frames)\n",
    "    print(f'Labels loaded: {len(train_labels)}')\n",
    "    return train_labels\n",
    "\n",
    "\n",
    "def get_cluster_id(volume_clusters, vol):\n",
    "    for id, lower_bound, upper_bound in volume_clusters:\n",
    "        if vol >= lower_bound and vol < upper_bound:\n",
    "            return id\n",
    "    return -1\n",
    "\n",
    "\n",
    "def get_cluster_ids(volume_clusters, df, group_fields):\n",
    "    df_groups = df.groupby(group_fields).sum()[['vol']]\n",
    "    df_groups = df_groups.reset_index()\n",
    "    df_groups['cluster'] = [get_cluster_id(volume_clusters, vol) for vol in df_groups['vol']]\n",
    "    return df_groups\n",
    "\n",
    "\n",
    "def load_tests(city):\n",
    "    test_input = pandas.read_parquet(BASEDIR / 'test' / city / 'input' / 'counters_test.parquet')\n",
    "    test_input['vol'] = np.array(test_input['volumes_1h'].to_numpy().tolist()).sum(axis=1)\n",
    "    return test_input\n",
    "\n",
    "\n",
    "def find_volume_clusters(city):\n",
    "    df = load_train_input(city)\n",
    "    return compute_volume_clusters(df)\n",
    "\n",
    "\n",
    "def compute_volume_clusters(df):\n",
    "    df_groups = df.groupby(['day', 't']).sum()[['vol']]\n",
    "    quants = list(df_groups.quantile(np.linspace(0, 1, NUM_VOLUME_CLUSTERS + 1))['vol'])\n",
    "    quants[0] -= 1e5\n",
    "    quants[-1] += 1e5\n",
    "    clusters = []\n",
    "    for i, l, h in zip(range(len(quants)-1), quants[:-1], quants[1:]):\n",
    "        clusters.append((i, l, h))\n",
    "    return clusters\n",
    "\n",
    "\n",
    "# Derived values from loop counter volumes\n",
    "STATIC_VOLUME_CLUSTERS = {\n",
    "    1: {\n",
    "        'london': [(0, -46599.0, 7806420.0)],\n",
    "        'madrid': [(0, 263688.0, 12361861.0)],\n",
    "        'melbourne': [(0, 35418.79999999999, 6885818.7)]\n",
    "    },\n",
    "    10: {\n",
    "        'london': [\n",
    "            (0, -46599.0, 932240.2999999999),\n",
    "            (1, 932240.2999999999, 1554726.4),\n",
    "            (2, 1554726.4, 2588921.9000000004),\n",
    "            (3, 2588921.9000000004, 3921954.0),\n",
    "            (4, 3921954.0, 4863117.5),\n",
    "            (5, 4863117.5, 5771968.0),\n",
    "            (6, 5771968.0, 6005322.7),\n",
    "            (7, 6005322.7, 6232288.4),\n",
    "            (8, 6232288.4, 6493853.5),\n",
    "            (9, 6493853.5, 7806420.0)\n",
    "        ],\n",
    "        'madrid': [\n",
    "            (0, 263688.0, 923316.4),\n",
    "            (1, 923316.4, 1911206.0),\n",
    "            (2, 1911206.0, 3344747.900000001),\n",
    "            (3, 3344747.900000001, 4972842.2),\n",
    "            (4, 4972842.2, 6422392.0),\n",
    "            (5, 6422392.0, 7669201.8),\n",
    "            (6, 7669201.8, 8975374.4),\n",
    "            (7, 8975374.4, 9762011.8),\n",
    "            (8, 9762011.8, 10563257.9),\n",
    "            (9, 10563257.9, 12361861.0)\n",
    "        ],\n",
    "        'melbourne': [\n",
    "            (0, 35418.79999999999, 344195.01666666666),\n",
    "            (1, 344195.01666666666, 588418.9400000001),\n",
    "            (2, 588418.9400000001, 1072442.9133333336),\n",
    "            (3, 1072442.9133333336, 1817113.62),\n",
    "            (4, 1817113.62, 2663038.05),\n",
    "            (5, 2663038.05, 3292800.466666667),\n",
    "            (6, 3292800.466666667, 3936777.729999998),\n",
    "            (7, 3936777.729999998, 4662487.213333336),\n",
    "            (8, 4662487.213333336, 5325993.843333334),\n",
    "            (9, 5325993.843333334, 6885818.7)\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "if NUM_VOLUME_CLUSTERS in STATIC_VOLUME_CLUSTERS:\n",
    "    city_volume_clusters = STATIC_VOLUME_CLUSTERS[NUM_VOLUME_CLUSTERS]\n",
    "else:\n",
    "    print('Computing volume clusters:')\n",
    "    city_volume_clusters = {\n",
    "        'london': find_volume_clusters('london'),\n",
    "        'madrid': find_volume_clusters('madrid'),\n",
    "        'melbourne': find_volume_clusters('melbourne')\n",
    "    }\n",
    "print(city_volume_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4da894b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prediction(city):\n",
    "    snapshot_file = BASEDIR / 'snapshots' / f'eta_volume_cluster_baseline_{EXPERIMENT_NAME}_{city}.parquet'\n",
    "    if USE_ETA_BASELINE_SNAPSHOTS:\n",
    "        median_etas_df = pandas.read_parquet(snapshot_file)\n",
    "    else:\n",
    "        train_inputs_df = load_train_input(city)\n",
    "        print(f'Inputs: {len(train_inputs_df)}')\n",
    "        cluster_dates_df = get_cluster_ids(city_volume_clusters[city], train_inputs_df, ['day', 't'])\n",
    "        print(f'Inputs grouped: {len(cluster_dates_df)}')\n",
    "        train_labels_df = load_train_labels(city)\n",
    "        print(f'Labels: {len(train_labels_df)}')\n",
    "        train_labels_df = train_labels_df.merge(cluster_dates_df, on=['day', 't'])\n",
    "        print(f'Labels merged: {len(train_labels_df)}')\n",
    "        print(f'Unique supersegments: {len(train_labels_df[\"identifier\"].unique())}')\n",
    "        train_labels_df = train_labels_df[['identifier', 'cluster', 'eta']]\n",
    "        median_etas_df = train_labels_df.groupby(['identifier', 'cluster']).median('eta')\n",
    "        median_etas_df = median_etas_df.reset_index()\n",
    "        print(f'Median ETAs: {len(median_etas_df)}')\n",
    "        snapshot_file.parent.mkdir(exist_ok=True, parents=True)\n",
    "        median_etas_df.to_parquet(snapshot_file, compression='snappy')\n",
    "        \n",
    "    tests_df = get_cluster_ids(city_volume_clusters[city], load_tests(city), ['test_idx'])\n",
    "    print(f'Test raw: {len(tests_df)}')\n",
    "    tests_df = tests_df.merge(median_etas_df, on=['cluster'], how='left')\n",
    "    print(f'Test ETAs: {len(tests_df)}')\n",
    "    submission_folder = BASEDIR / 'submissions' / EXPERIMENT_NAME / city / 'labels'\n",
    "    submission_folder.mkdir(exist_ok=True, parents=True)\n",
    "    tests_df.to_parquet(submission_folder / 'eta_labels_test.parquet', compression='snappy')\n",
    "    return tests_df[['identifier', 'eta', 'test_idx']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e9297d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 110 training input files for london\n",
      "Inputs: 36503376\n",
      "Inputs grouped: 10544\n",
      "Read 110 training label files\n",
      "Labels loaded: 42366720\n",
      "Labels: 42366720\n",
      "Labels merged: 42302528\n",
      "Unique supersegments: 4012\n",
      "Median ETAs: 40120\n",
      "Test raw: 100\n",
      "Test ETAs: 401200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>eta</th>\n",
       "      <th>test_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102046,107792</td>\n",
       "      <td>951.533407</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102046,1231977903</td>\n",
       "      <td>439.876163</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102046,1504500003</td>\n",
       "      <td>216.813861</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102046,1635822092</td>\n",
       "      <td>203.559885</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102046,1691133703</td>\n",
       "      <td>353.472554</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401195</th>\n",
       "      <td>99301644,4773877783</td>\n",
       "      <td>473.290888</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401196</th>\n",
       "      <td>99301644,6022727128</td>\n",
       "      <td>337.494930</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401197</th>\n",
       "      <td>99301644,6225598610</td>\n",
       "      <td>551.574208</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401198</th>\n",
       "      <td>99301644,6225784831</td>\n",
       "      <td>489.879028</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401199</th>\n",
       "      <td>99301644,6245856720</td>\n",
       "      <td>297.437628</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>401200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 identifier         eta  test_idx\n",
       "0             102046,107792  951.533407         0\n",
       "1         102046,1231977903  439.876163         0\n",
       "2         102046,1504500003  216.813861         0\n",
       "3         102046,1635822092  203.559885         0\n",
       "4         102046,1691133703  353.472554         0\n",
       "...                     ...         ...       ...\n",
       "401195  99301644,4773877783  473.290888        99\n",
       "401196  99301644,6022727128  337.494930        99\n",
       "401197  99301644,6225598610  551.574208        99\n",
       "401198  99301644,6225784831  489.879028        99\n",
       "401199  99301644,6245856720  297.437628        99\n",
       "\n",
       "[401200 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_prediction('london')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ba969d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 109 training input files for madrid\n",
      "Inputs: 38337732\n",
      "Inputs grouped: 10448\n",
      "Read 109 training label files\n",
      "Labels loaded: 41531616\n",
      "Labels: 41531616\n",
      "Labels merged: 41468112\n",
      "Unique supersegments: 3969\n",
      "Median ETAs: 39690\n",
      "Test raw: 100\n",
      "Test ETAs: 396900\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>eta</th>\n",
       "      <th>test_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100890241,25531147</td>\n",
       "      <td>390.770165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100890241,25552352</td>\n",
       "      <td>333.217795</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100890241,25934553</td>\n",
       "      <td>371.828689</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100890241,26066556</td>\n",
       "      <td>548.296091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100890241,26412872</td>\n",
       "      <td>576.546697</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396895</th>\n",
       "      <td>98989165,25906850</td>\n",
       "      <td>463.547558</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396896</th>\n",
       "      <td>98989165,26412824</td>\n",
       "      <td>555.803452</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396897</th>\n",
       "      <td>98989165,27509101</td>\n",
       "      <td>475.162506</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396898</th>\n",
       "      <td>98989165,29803013</td>\n",
       "      <td>131.186546</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396899</th>\n",
       "      <td>98989165,335642218</td>\n",
       "      <td>391.114996</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>396900 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                identifier         eta  test_idx\n",
       "0       100890241,25531147  390.770165         0\n",
       "1       100890241,25552352  333.217795         0\n",
       "2       100890241,25934553  371.828689         0\n",
       "3       100890241,26066556  548.296091         0\n",
       "4       100890241,26412872  576.546697         0\n",
       "...                    ...         ...       ...\n",
       "396895   98989165,25906850  463.547558        99\n",
       "396896   98989165,26412824  555.803452        99\n",
       "396897   98989165,27509101  475.162506        99\n",
       "396898   98989165,29803013  131.186546        99\n",
       "396899  98989165,335642218  391.114996        99\n",
       "\n",
       "[396900 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_prediction('madrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05215089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 106 training input files for melbourne\n",
      "Inputs: 39664688\n",
      "Inputs grouped: 10160\n",
      "Read 108 training label files\n",
      "Labels loaded: 33654528\n",
      "Labels: 33654528\n",
      "Labels merged: 32979360\n",
      "Unique supersegments: 3246\n",
      "Median ETAs: 32460\n",
      "Test raw: 100\n",
      "Test ETAs: 324600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>eta</th>\n",
       "      <th>test_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102356196,1661825888</td>\n",
       "      <td>95.428332</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102356196,27170602</td>\n",
       "      <td>138.613647</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102356196,29708589</td>\n",
       "      <td>116.605973</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102356196,29708590</td>\n",
       "      <td>158.550847</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102356196,342826772</td>\n",
       "      <td>101.447276</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324595</th>\n",
       "      <td>9644475963,1694288769</td>\n",
       "      <td>166.700150</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324596</th>\n",
       "      <td>9644475963,1694312194</td>\n",
       "      <td>192.888583</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324597</th>\n",
       "      <td>9644475963,292434014</td>\n",
       "      <td>71.329040</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324598</th>\n",
       "      <td>9644475963,30266272</td>\n",
       "      <td>89.451022</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324599</th>\n",
       "      <td>9644475963,317326594</td>\n",
       "      <td>89.261101</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>324600 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   identifier         eta  test_idx\n",
       "0        102356196,1661825888   95.428332         0\n",
       "1          102356196,27170602  138.613647         0\n",
       "2          102356196,29708589  116.605973         0\n",
       "3          102356196,29708590  158.550847         0\n",
       "4         102356196,342826772  101.447276         0\n",
       "...                       ...         ...       ...\n",
       "324595  9644475963,1694288769  166.700150        99\n",
       "324596  9644475963,1694312194  192.888583        99\n",
       "324597   9644475963,292434014   71.329040        99\n",
       "324598    9644475963,30266272   89.451022        99\n",
       "324599   9644475963,317326594   89.261101        99\n",
       "\n",
       "[324600 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_prediction('melbourne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39a5eae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/t4c_2022_comp_data/submissions/exp_c10/london/labels/:\r\n",
      "total 6568\r\n",
      "-rw-r--r--  1 neun  staff  3151921 Sep  1 10:33 eta_labels_test.parquet\r\n",
      "\r\n",
      "/tmp/t4c_2022_comp_data/submissions/exp_c10/madrid/labels/:\r\n",
      "total 7208\r\n",
      "-rw-r--r--  1 neun  staff  3463285 Sep  1 10:34 eta_labels_test.parquet\r\n",
      "\r\n",
      "/tmp/t4c_2022_comp_data/submissions/exp_c10/melbourne/labels/:\r\n",
      "total 7088\r\n",
      "-rw-r--r--  1 neun  staff  2586338 Sep  1 10:35 eta_labels_test.parquet\r\n"
     ]
    }
   ],
   "source": [
    "! ls -l {BASEDIR}/submissions/{EXPERIMENT_NAME}/**/labels/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1589885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing submission ZIP file for /tmp/t4c_2022_comp_data/submissions/exp_c10\n",
      "updating: london/ (stored 0%)\n",
      "updating: london/labels/ (stored 0%)\n",
      "updating: london/labels/eta_labels_test.parquet (deflated 65%)\n",
      "updating: madrid/ (stored 0%)\n",
      "updating: madrid/labels/ (stored 0%)\n",
      "updating: madrid/labels/eta_labels_test.parquet (deflated 67%)\n",
      "updating: melbourne/ (stored 0%)\n",
      "updating: melbourne/labels/ (stored 0%)\n",
      "updating: melbourne/labels/eta_labels_test.parquet (deflated 62%)\n",
      "total 6288\n",
      "-rw-r--r--  1 neun  staff  3215855 Sep  1 10:35 eta_volume_cluster_baseline_exp_c10.zip\n",
      "drwxr-xr-x  3 neun  staff       96 Aug 31 18:31 london\n",
      "drwxr-xr-x  3 neun  staff       96 Aug 31 18:32 madrid\n",
      "drwxr-xr-x  3 neun  staff       96 Aug 31 18:33 melbourne\n"
     ]
    }
   ],
   "source": [
    "%%bash -s {BASEDIR} {EXPERIMENT_NAME}\n",
    "\n",
    "cd  $1/submissions/$2\n",
    "echo \"Preparing submission ZIP file for $PWD\"\n",
    "\n",
    "zip -r eta_volume_cluster_baseline_$2.zip london madrid melbourne\n",
    "\n",
    "ls -l"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.11.2"
   }
  },
  "kernelspec": {
   "display_name": "Python [conda env:t4c] *",
   "language": "python",
   "name": "conda-env-t4c-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
