{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "615274c4-49ff-48a4-a97f-b9cb8dec6bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# os.path.join(os.path.dirname(__file__)\n",
    "sys.path.append(\"../\")  # location of config file\n",
    "sys.path.append(\"../../\") # working directory inside exploration\n",
    "sys.path.append(\"../../../\") \n",
    "\n",
    "\n",
    "\n",
    "import config\n",
    "\n",
    "os.chdir(\"../../\")\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "from smartprint import smartprint as sprint\n",
    "from preprocessing.ProcessRaw import ProcessRaw\n",
    "from smartprint import smartprint as sprint\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b1b1d6f-cee7-4b2f-81ca-7968f590f1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! rm -rf dist_plots\n",
    "# ! mkdir dist_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04ba516a-ee88-45ca-a31c-a5e89c74e79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "london_45_days processed:  91%|█████████▏| 215/235 [00:00<00:00, 14628.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_date, end_date : 2020-02-01 2020-01-31\n",
      "\"Reached end of dates, skipping....Total #dates processed=\", len(dates) : Reached end of dates, skipping....Total #dates processed= 215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niskumar/NeurIPS2022-traffic4cast/train_data_all_cities/london-1-1-45-:   0%|          | 0/215 [00:00<?, ?it/s]\n",
      "Repeating N times: 100%|██████████| 30/30 [05:49<00:00, 11.64s/it]\n",
      "london_105_days processed:  91%|█████████▏| 215/235 [00:00<00:00, 13326.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_date, end_date : 2020-02-01 2020-01-31\n",
      "\"Reached end of dates, skipping....Total #dates processed=\", len(dates) : Reached end of dates, skipping....Total #dates processed= 215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niskumar/NeurIPS2022-traffic4cast/train_data_all_cities/london-1-1-105-:   0%|          | 0/215 [00:00<?, ?it/s]\n",
      "Repeating N times: 100%|██████████| 30/30 [06:55<00:00, 13.85s/it]\n",
      "london_205_days processed:  91%|█████████▏| 215/235 [00:00<00:00, 14221.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_date, end_date : 2020-02-01 2020-01-31\n",
      "\"Reached end of dates, skipping....Total #dates processed=\", len(dates) : Reached end of dates, skipping....Total #dates processed= 215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niskumar/NeurIPS2022-traffic4cast/train_data_all_cities/london-1-1-205-:   0%|          | 0/215 [00:00<?, ?it/s]\n",
      "Repeating N times: 100%|██████████| 30/30 [10:08<00:00, 20.28s/it]\n",
      "madrid_45_days processed:  91%|█████████ | 214/235 [00:00<00:00, 14420.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_date, end_date : 2022-01-01 2021-12-31\n",
      "\"Reached end of dates, skipping....Total #dates processed=\", len(dates) : Reached end of dates, skipping....Total #dates processed= 214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niskumar/NeurIPS2022-traffic4cast/train_data_all_cities/madrid-1-1-45-:   0%|          | 0/214 [00:00<?, ?it/s]\n",
      "Repeating N times: 100%|██████████| 30/30 [05:54<00:00, 11.81s/it]\n",
      "madrid_105_days processed:  91%|█████████ | 214/235 [00:00<00:00, 17230.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_date, end_date : 2022-01-01 2021-12-31\n",
      "\"Reached end of dates, skipping....Total #dates processed=\", len(dates) : Reached end of dates, skipping....Total #dates processed= 214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niskumar/NeurIPS2022-traffic4cast/train_data_all_cities/madrid-1-1-105-:   0%|          | 0/214 [00:00<?, ?it/s]\n",
      "Repeating N times: 100%|██████████| 30/30 [06:53<00:00, 13.80s/it]\n",
      "madrid_205_days processed:  91%|█████████ | 214/235 [00:00<00:00, 13508.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_date, end_date : 2022-01-01 2021-12-31\n",
      "\"Reached end of dates, skipping....Total #dates processed=\", len(dates) : Reached end of dates, skipping....Total #dates processed= 214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niskumar/NeurIPS2022-traffic4cast/train_data_all_cities/madrid-1-1-205-:   0%|          | 0/214 [00:00<?, ?it/s]\n",
      "Repeating N times:   7%|▋         | 2/30 [00:41<09:46, 20.93s/it]/tmp/ipykernel_1903560/2347523205.py:96: RuntimeWarning: invalid value encountered in divide\n",
      "  pdf_dist_sample = hist_sample / hist_sample.sum() + 1e-16\n",
      "Repeating N times: 100%|██████████| 30/30 [10:24<00:00, 20.81s/it]\n",
      "melbourne_45_days processed:  91%|█████████ | 213/235 [00:00<00:00, 14393.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_date, end_date : 2020-12-31 2020-12-30\n",
      "\"Reached end of dates, skipping....Total #dates processed=\", len(dates) : Reached end of dates, skipping....Total #dates processed= 213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niskumar/NeurIPS2022-traffic4cast/train_data_all_cities/melbourne-1-1-45-:   0%|          | 0/213 [00:00<?, ?it/s]\n",
      "Repeating N times: 100%|██████████| 30/30 [05:54<00:00, 11.82s/it]\n",
      "melbourne_105_days processed:  91%|█████████ | 213/235 [00:00<00:00, 17145.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_date, end_date : 2020-12-31 2020-12-30\n",
      "\"Reached end of dates, skipping....Total #dates processed=\", len(dates) : Reached end of dates, skipping....Total #dates processed= 213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niskumar/NeurIPS2022-traffic4cast/train_data_all_cities/melbourne-1-1-105-:   0%|          | 0/213 [00:00<?, ?it/s]\n",
      "Repeating N times: 100%|██████████| 30/30 [06:54<00:00, 13.83s/it]\n",
      "melbourne_205_days processed:  91%|█████████ | 213/235 [00:00<00:00, 13543.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_date, end_date : 2020-12-31 2020-12-30\n",
      "\"Reached end of dates, skipping....Total #dates processed=\", len(dates) : Reached end of dates, skipping....Total #dates processed= 213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niskumar/NeurIPS2022-traffic4cast/train_data_all_cities/melbourne-1-1-205-:   0%|          | 0/213 [00:00<?, ?it/s]\n",
      "Repeating N times: 100%|██████████| 30/30 [10:22<00:00, 20.75s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#########################################################################\n",
    "#################  tryout: smoothing and thresholds  ####################\n",
    "#########################################################################\n",
    "# ! pip install peakdetect==1.2\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "from scipy.stats import entropy\n",
    "\n",
    "def temporal_filter_simple(file_list, query_point, n, L):\n",
    "    \"\"\"\n",
    "    sample 2L points\n",
    "    n: the serial number identifier for query point\n",
    "    \"\"\"\n",
    "    if L == \"ALL\":\n",
    "        filename_range = range(len(file_list))\n",
    "    else:\n",
    "        filename_range = range(n-L, n+L)\n",
    "        \n",
    "    distance_list = []\n",
    "    \n",
    "    for i in filename_range:\n",
    "        if i == n:\n",
    "            # no need for 0 distance\n",
    "            continue\n",
    "        distance_list.append(np.max(np.abs(query_point - np.load(file_list[i]))))\n",
    "     \n",
    "    return distance_list\n",
    "\n",
    "\n",
    "\n",
    "def temporal_filter_advanced(file_list, query_point, n, L):\n",
    "    \"\"\"\n",
    "    sample 2L points\n",
    "    n: the serial number identifier for query point\n",
    "    \"\"\"\n",
    "    if L == \"ALL\":\n",
    "        filename_range = range(len(file_list))\n",
    "    else:\n",
    "        filename_range = []\n",
    "        for i in range(7):  # 7 days\n",
    "            filename_range.extend(  list (range(n + 96*i - L, n + 96*i + L))  )\n",
    "            \n",
    "    distance_list = []\n",
    "    \n",
    "    for i in filename_range:\n",
    "        if i == n:\n",
    "            # no need for 0 distance\n",
    "            continue\n",
    "        distance_list.append(np.max(np.abs(query_point - np.load(file_list[i]))))\n",
    "     \n",
    "    return distance_list\n",
    "    \n",
    "\n",
    "    \n",
    "which_func = temporal_filter_simple\n",
    "\n",
    "for cityname in [\"london\", \"Madrid\", \"Melbourne\"]:\n",
    "    for scale in [45, 105, 205]:\n",
    "        for i_o_length in [1]:\n",
    "            for pred_horiz in [1]: # [1]:\n",
    "                plt.clf()\n",
    "                \n",
    "                ProcessRaw(cityname=cityname, i_o_length=i_o_length, prediction_horizon=pred_horiz, grid_size=scale)\n",
    "                prefix = ProcessRaw.file_prefix(cityname, i_o_length, pred_horiz, scale)\n",
    "\n",
    "                file_list = glob.glob(\"../train_data_all_cities/\" + prefix + \"/*_x.npy\")\n",
    "                \n",
    "                # Here we need sorted file so that we can directly find the neighbours\n",
    "                file_list = sorted(file_list, key=lambda x: int(x.split('-')[-1].split('_x.npy')[0]))\n",
    "\n",
    "                        \n",
    "                symmetric_KL_div_list_stacked = []\n",
    "                for repeat in tqdm(range(30), desc=\"Repeating N times\"):\n",
    "                    symmetric_KL_div_list = []\n",
    "                    \n",
    "                    L_range = np.arange(1, 15*14, 1)\n",
    "                    BINS = np.arange(0, 7000, 100)\n",
    "                    \n",
    "                    # choose query point somewhere at least one week away from the \n",
    "                    # boundaries of the dataset; at least 96 * 7 away\n",
    "                    query_index = np.inf\n",
    "                    while (not 96 * 10 < query_index < 16000 - 96 * 7):\n",
    "                        n = int(np.random.rand() * len(file_list))\n",
    "                        query_point = np.load(file_list[n])\n",
    "                        query_index = int(file_list[n].split(\"/\")[-1].split(\"_x.npy\")[0].split(\"-\")[-1])\n",
    "                    \n",
    "                    distances = which_func(file_list, query_point, n, \"ALL\")\n",
    "                    hist_all = np.histogram(distances, bins=BINS)[0]\n",
    "                    pdf_dist_all = hist_all / hist_all.sum() + 1e-16                        \n",
    "                    \n",
    "                    for L in L_range:\n",
    "    \n",
    "                        distances = which_func(file_list, query_point, n, L)\n",
    "                        \n",
    "                        hist_sample = np.histogram(distances, bins=BINS)[0]\n",
    "                        pdf_dist_sample = hist_sample / hist_sample.sum() + 1e-16\n",
    "\n",
    "                        symmetric_KL_div = entropy(pdf_dist_sample, pdf_dist_all) + \\\n",
    "                                           entropy(pdf_dist_all, pdf_dist_sample) \n",
    "\n",
    "                        symmetric_KL_div_list.append(symmetric_KL_div)\n",
    "                    \n",
    "                        # live plot to see progress as more points are added\n",
    "                        # plt.plot(symmetric_KL_div_list, alpha=0.5)\n",
    "                        # plt.savefig(\"dist_plots/\" + \"Single point KL-div (whole data, sample) \\n\"+prefix + \".png\")\n",
    "                        \n",
    "                    symmetric_KL_div_list_stacked.append(symmetric_KL_div_list)\n",
    "                    \n",
    "                    plt.plot(L_range, symmetric_KL_div_list, alpha=0.3)\n",
    "                    \n",
    "                plt.plot(L_range, np.median(np.array(symmetric_KL_div_list_stacked), axis=0), \\\n",
    "                     alpha=1, color=\"black\", label=\"Median\")\n",
    "                plt.xlabel(\"sample size(N)\")\n",
    "                plt.xticks(list(range(1, 200, 50)), rotation=90, fontsize=8)\n",
    "                plt.legend()\n",
    "                plt.title(\"Single point KL-div whole data vs sample pdf \\n\"+prefix)\n",
    "                plt.savefig(\"dist_plots/Comb-\"+str(which_func)\\\n",
    "                            + \"Single point KL-div (whole data, sample) \\n\"+prefix + \".png\")\n",
    "                plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d618a8d6-853a-4eaa-bff4-52f3ed8b2810",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64b43de5-a9fa-4668-9a42-94f97dc80999",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "london_45_days processed:  91%|█████████▏| 215/235 [00:00<00:00, 14678.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_date, end_date : 2020-02-01 2020-01-31\n",
      "\"Reached end of dates, skipping....Total #dates processed=\", len(dates) : Reached end of dates, skipping....Total #dates processed= 215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niskumar/NeurIPS2022-traffic4cast/train_data_all_cities/london-1-1-45-:   0%|          | 0/215 [00:00<?, ?it/s]\n",
      "Repeating N times: 100%|██████████| 30/30 [01:43<00:00,  3.44s/it]\n",
      "london_105_days processed:  91%|█████████▏| 215/235 [00:00<00:00, 14719.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_date, end_date : 2020-02-01 2020-01-31\n",
      "\"Reached end of dates, skipping....Total #dates processed=\", len(dates) : Reached end of dates, skipping....Total #dates processed= 215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niskumar/NeurIPS2022-traffic4cast/train_data_all_cities/london-1-1-105-:   0%|          | 0/215 [00:00<?, ?it/s]\n",
      "Repeating N times: 100%|██████████| 30/30 [02:02<00:00,  4.10s/it]\n",
      "london_205_days processed:  91%|█████████▏| 215/235 [00:00<00:00, 17916.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_date, end_date : 2020-02-01 2020-01-31\n",
      "\"Reached end of dates, skipping....Total #dates processed=\", len(dates) : Reached end of dates, skipping....Total #dates processed= 215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niskumar/NeurIPS2022-traffic4cast/train_data_all_cities/london-1-1-205-:   0%|          | 0/215 [00:00<?, ?it/s]\n",
      "Repeating N times: 100%|██████████| 30/30 [02:54<00:00,  5.83s/it]\n",
      "madrid_45_days processed:  91%|█████████ | 214/235 [00:00<00:00, 18175.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_date, end_date : 2022-01-01 2021-12-31\n",
      "\"Reached end of dates, skipping....Total #dates processed=\", len(dates) : Reached end of dates, skipping....Total #dates processed= 214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niskumar/NeurIPS2022-traffic4cast/train_data_all_cities/madrid-1-1-45-:   0%|          | 0/214 [00:00<?, ?it/s]\n",
      "Repeating N times: 100%|██████████| 30/30 [01:42<00:00,  3.40s/it]\n",
      "madrid_105_days processed:  91%|█████████ | 214/235 [00:00<00:00, 18053.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_date, end_date : 2022-01-01 2021-12-31\n",
      "\"Reached end of dates, skipping....Total #dates processed=\", len(dates) : Reached end of dates, skipping....Total #dates processed= 214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niskumar/NeurIPS2022-traffic4cast/train_data_all_cities/madrid-1-1-105-:   0%|          | 0/214 [00:00<?, ?it/s]\n",
      "Repeating N times: 100%|██████████| 30/30 [02:01<00:00,  4.06s/it]\n",
      "madrid_205_days processed:  91%|█████████ | 214/235 [00:00<00:00, 14682.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_date, end_date : 2022-01-01 2021-12-31\n",
      "\"Reached end of dates, skipping....Total #dates processed=\", len(dates) : Reached end of dates, skipping....Total #dates processed= 214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niskumar/NeurIPS2022-traffic4cast/train_data_all_cities/madrid-1-1-205-:   0%|          | 0/214 [00:00<?, ?it/s]\n",
      "Repeating N times: 100%|██████████| 30/30 [03:02<00:00,  6.08s/it]\n",
      "melbourne_45_days processed:  91%|█████████ | 213/235 [00:00<00:00, 17177.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_date, end_date : 2020-12-31 2020-12-30\n",
      "\"Reached end of dates, skipping....Total #dates processed=\", len(dates) : Reached end of dates, skipping....Total #dates processed= 213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niskumar/NeurIPS2022-traffic4cast/train_data_all_cities/melbourne-1-1-45-:   0%|          | 0/213 [00:00<?, ?it/s]\n",
      "Repeating N times: 100%|██████████| 30/30 [01:42<00:00,  3.41s/it]\n",
      "melbourne_105_days processed:  91%|█████████ | 213/235 [00:00<00:00, 17125.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_date, end_date : 2020-12-31 2020-12-30\n",
      "\"Reached end of dates, skipping....Total #dates processed=\", len(dates) : Reached end of dates, skipping....Total #dates processed= 213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niskumar/NeurIPS2022-traffic4cast/train_data_all_cities/melbourne-1-1-105-:   0%|          | 0/213 [00:00<?, ?it/s]\n",
      "Repeating N times: 100%|██████████| 30/30 [02:02<00:00,  4.09s/it]\n",
      "melbourne_205_days processed:  91%|█████████ | 213/235 [00:00<00:00, 17438.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_date, end_date : 2020-12-31 2020-12-30\n",
      "\"Reached end of dates, skipping....Total #dates processed=\", len(dates) : Reached end of dates, skipping....Total #dates processed= 213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niskumar/NeurIPS2022-traffic4cast/train_data_all_cities/melbourne-1-1-205-:   0%|          | 0/213 [00:00<?, ?it/s]\n",
      "Repeating N times: 100%|██████████| 30/30 [03:03<00:00,  6.10s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " \n",
    "which_func = temporal_filter_advanced\n",
    "\n",
    "for cityname in [\"london\", \"Madrid\", \"Melbourne\"]:\n",
    "    for scale in [45, 105, 205]:\n",
    "        for i_o_length in [1]:\n",
    "            for pred_horiz in [1]: # [1]\n",
    "                plt.clf()\n",
    "                \n",
    "                ProcessRaw(cityname=cityname, i_o_length=i_o_length, prediction_horizon=pred_horiz, grid_size=scale)\n",
    "                prefix = ProcessRaw.file_prefix(cityname, i_o_length, pred_horiz, scale)\n",
    "\n",
    "                file_list = glob.glob(\"../train_data_all_cities/\" + prefix + \"/*_x.npy\")\n",
    "                \n",
    "                # Here we need sorted file so that we can directly find the neighbours\n",
    "                file_list = sorted(file_list, key=lambda x: int(x.split('-')[-1].split('_x.npy')[0]))\n",
    "\n",
    "                        \n",
    "                symmetric_KL_div_list_stacked = []\n",
    "                for repeat in tqdm(range(30), desc=\"Repeating N times\"):\n",
    "                    symmetric_KL_div_list = []\n",
    "                    \n",
    "                    L_range = np.arange(1, 15, 1)\n",
    "                    BINS = np.arange(0, 7000, 100)\n",
    "                    \n",
    "                    # choose query point somewhere at least one week away from the \n",
    "                    # boundaries of the dataset; at least 96 * 7 away\n",
    "                    query_index = np.inf\n",
    "                    while (not 96 * 10 < query_index < 16000 - 96 * 7):\n",
    "                        n = int(np.random.rand() * len(file_list))\n",
    "                        query_point = np.load(file_list[n])\n",
    "                        query_index = int(file_list[n].split(\"/\")[-1].split(\"_x.npy\")[0].split(\"-\")[-1])\n",
    "                    \n",
    "                    distances = which_func(file_list, query_point, n, \"ALL\")\n",
    "                    hist_all = np.histogram(distances, bins=BINS)[0]\n",
    "                    pdf_dist_all = hist_all / hist_all.sum() + 1e-16                        \n",
    "                    \n",
    "                    for L in L_range:\n",
    "    \n",
    "                        distances = which_func(file_list, query_point, n, L)\n",
    "                        \n",
    "                        hist_sample = np.histogram(distances, bins=BINS)[0]\n",
    "                        pdf_dist_sample = hist_sample / hist_sample.sum() + 1e-16\n",
    "\n",
    "                        symmetric_KL_div = entropy(pdf_dist_sample, pdf_dist_all) + \\\n",
    "                                           entropy(pdf_dist_all, pdf_dist_sample) \n",
    "\n",
    "                        symmetric_KL_div_list.append(symmetric_KL_div)\n",
    "                    \n",
    "                        # live plot to see progress as more points are added\n",
    "                        # plt.plot(symmetric_KL_div_list, alpha=0.5)\n",
    "                        # plt.savefig(\"dist_plots/\" + \"Single point KL-div (whole data, sample) \\n\"+prefix + \".png\")\n",
    "                        \n",
    "                    symmetric_KL_div_list_stacked.append(symmetric_KL_div_list)\n",
    "                    \n",
    "                    plt.plot(L_range, symmetric_KL_div_list, alpha=0.3)\n",
    "                    \n",
    "                plt.plot(L_range, np.median(np.array(symmetric_KL_div_list_stacked), axis=0), \\\n",
    "                     alpha=1, color=\"black\", label=\"Median\")\n",
    "                plt.xlabel(\"sample size(N)\")\n",
    "                plt.xticks(list(range(1, 200, 50)), rotation=90, fontsize=8)\n",
    "                plt.legend()\n",
    "                plt.title(\"Single point KL-div whole data vs sample pdf \\n\"+prefix)\n",
    "                plt.savefig(\"dist_plots/Comb-\"+str(which_func)\\\n",
    "                            + \"Single point KL-div (whole data, sample) \\n\"+prefix + \".png\")\n",
    "                plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f27048-aa6c-482e-97c9-03c02156dc19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00748bfc-1a00-4fab-9b57-47080b8b5b74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "459e4a8e-a033-4638-9d5a-0d5bbdf1b621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/niskumar/NeurIPS2022-traffic4cast/exploration\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c48ab22-4151-4bdb-9a93-0078353c08c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942ee717-3f80-4e1b-9155-84228ee7f716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64808141-55b5-417a-95f1-e43bb5c8a686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d11167c-f9ab-4da6-99c0-4fea86039d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140080bc-1265-4835-a655-a97a7a9f3644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b727e2-b398-4ea1-b13b-10341496fce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9c5c01-9a37-4772-bb3e-45e7924c004e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd8d3cf-5001-454a-b204-91663df0befc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
