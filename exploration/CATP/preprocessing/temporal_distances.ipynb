{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6331b63-3522-4eb1-b4a7-0778d400a203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# os.path.join(os.path.dirname(__file__)\n",
    "sys.path.append(\"../\")  # location of config file\n",
    "sys.path.append(\"../../\") \n",
    "\n",
    "\n",
    "import config\n",
    "\n",
    "os.chdir(\"../../\") # working directory inside exploration\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "from smartprint import smartprint as sprint\n",
    "from preprocessing.ProcessRaw import ProcessRaw\n",
    "from smartprint import smartprint as sprint\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89029c97-ec92-457b-83fa-5f8b4e29f1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_color = {\"london\" : \"red\", \n",
    "             \"melbourne\": \"blue\",\n",
    "             \"madrid\": \"green\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b04966-2458-4005-a76a-d6887d0bedea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cd3228-f7df-4693-a310-87d0602d110f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c7703e-3df8-4cfc-b07f-72287e3e32c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9797b6-5ff1-4b47-a53e-1f086368791c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1f35bd-a34a-4dd9-bd20-9a42a72ce216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6552167-ab82-4ff3-b5e1-6c6459f086a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "london 4 1 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "london_55_days processed:  91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                     | 215/235 [00:00<00:00, 729.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_date, end_date : 2020-02-01 2020-01-31\n",
      "\"Reached end of dates, skipping....Total #dates processed=\", len(dates) : Reached end of dates, skipping....Total #dates processed= 215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nishant/Downloads/NeurIPS2022-traffic4cast/train_data_all_cities/london-4-1-55-:   0%|                                                                                                                                                                                                   | 0/215 [00:00<?, ?it/s]\n",
      "Iterating over 100 random source files:   0%|                                                                                                                                                                                                                                                   | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 30\u001b[0m\n\u001b[1;32m     22\u001b[0m dist_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# choose_filename until we get something in the middle of the dataset so that \u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# we can iterate over weeks\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m source_file \u001b[38;5;241m=\u001b[39m \u001b[43mfilenameslist\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     31\u001b[0m source_x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(source_file)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# integer id of filename\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for city_ in config.city_list:\n",
    "    city = city_.lower() \n",
    "    for io_len in [4]: # range(1,9):\n",
    "        for pred_horiz in [1]: # config.pred_horiz_def:\n",
    "            for scale in config.scales_def:\n",
    "                print (city, io_len, pred_horiz, scale)\n",
    "\n",
    "                prefix = ProcessRaw.file_prefix(cityname=city, io_length=io_len, pred_horiz=pred_horiz, scale=scale)\n",
    "\n",
    "                obj = ProcessRaw(cityname=city, i_o_length=io_len, prediction_horizon=pred_horiz, grid_size=scale)\n",
    "                    \n",
    "                folderpath = os.path.join(config.DATA_FOLDER, config.train_folder_name, prefix)\n",
    "                filenameslist = glob.glob(folderpath + \"/*_x.npy\")\n",
    "                \n",
    "                random.shuffle(filenameslist)\n",
    "                \n",
    "                \n",
    "                multiple_source_distance_list = []\n",
    "                for _ in tqdm(range(100), desc=\"Iterating over 100 random source files\"):\n",
    "                    random.shuffle(filenameslist) # inefficient method of choosing a random filename\n",
    "                    \n",
    "                    dist_list = []\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    # choose_filename until we get something in the middle of the dataset so that \n",
    "                    # we can iterate over weeks\n",
    "                    \n",
    "                    \n",
    "                    source_file = filenameslist[0]\n",
    "                    source_x = np.load(source_file)\n",
    "                    # integer id of filename\n",
    "                    n = int(source_file.split(prefix)[-1].replace(\"_x.npy\", \"\"))\n",
    "                    \n",
    "                    while ( n - 14 * obj.offset < 0 or n + 14 * obj.offset > 8500 ): # 8500 number of training data points across all scenarios.\n",
    "                        # keep looking for a source point near the centre of the dataset \n",
    "                        # so that we can look one week ahead and behind\n",
    "                        \n",
    "                        random.shuffle(filenameslist) # inefficient method of choosing a random filename\n",
    "                        \n",
    "                        source_file = filenameslist[0]\n",
    "                        # integer id of filename\n",
    "                        n = int(source_file.split(prefix)[-1].replace(\"_x.npy\", \"\"))\n",
    "                        source_x = np.load(source_file)\n",
    "\n",
    "                        \n",
    "                    # sprint (n)\n",
    "\n",
    "                    # Now, we iterate through one week of temporal neighbours\n",
    "                    # 2 weeks before and 2 weeks after\n",
    "                    for i in range(n-14*obj.offset, n+14*obj.offset):\n",
    "\n",
    "                        neighbour_filename = (source_file.split(prefix)[0] + \\\n",
    "                                   prefix + \\\n",
    "                                   source_file.split(prefix)[1] + \\\n",
    "                                   prefix + \\\n",
    "                                   str(i) + \"_x.npy\")\n",
    "                        neighbour = np.load(neighbour_filename)\n",
    "                        \n",
    "                        dist_list.append (np.max(np.abs( neighbour - source_x)) )\n",
    "                        \n",
    "                    multiple_source_distance_list.append(dist_list)\n",
    "                    plt.plot(range(-14*obj.offset, 14*obj.offset), (dist_list), alpha=0.01, color=city_color[city])\n",
    "                    \n",
    "                multiple_source_distance_list = np.array(multiple_source_distance_list)\n",
    "                \n",
    "                mean_plot = (np.mean(multiple_source_distance_list, axis=0))\n",
    "                plt.plot(range(-14*obj.offset, +14*obj.offset), (mean_plot), label= prefix + \" mean plot \", color=city_color[city])\n",
    "                \n",
    "                # median_plot = (np.median(multiple_source_distance_list, axis=0))\n",
    "                # plt.plot(np.convolve(median_plot, [1/1]*1, \"valid\"), label= prefix + \" median plot \")\n",
    "                \n",
    "                \n",
    "                sprint (prefix)\n",
    "            #     break\n",
    "            # break\n",
    "        # break\n",
    "    # break\n",
    "plt.ylabel(r'$\\|x_t-x_{t{\\pm}h}\\|L_{\\infty}$', fontsize=15)\n",
    "plt.legend(fontsize=15)\n",
    "plt.xlabel(\"Time stamps (15 min resolution)\")\n",
    "plt.yscale('log')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"city_list_scales_4_1.png\", dpi=600)\n",
    "plt.show()   # obj._clean_intermediate_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ed0ad78-be5c-4da7-9919-bb31ee258185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98493668-6441-4f49-b600-c0d859cdf80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/nishant/Downloads/NeurIPS2022-traffic4cast/train_data_all_cities/london-4-1-55-'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folderpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873bd30a-8de9-4e41-93cc-41f1c46f688a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
