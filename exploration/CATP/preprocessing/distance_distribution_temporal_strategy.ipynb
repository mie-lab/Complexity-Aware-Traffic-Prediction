{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "615274c4-49ff-48a4-a97f-b9cb8dec6bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# os.path.join(os.path.dirname(__file__)\n",
    "sys.path.append(\"../\")  # location of config file\n",
    "sys.path.append(\"../../\") # working directory inside exploration\n",
    "sys.path.append(\"../../../\") \n",
    "\n",
    "\n",
    "\n",
    "import config\n",
    "\n",
    "os.chdir(\"../../\")\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "from smartprint import smartprint as sprint\n",
    "from preprocessing.ProcessRaw import ProcessRaw\n",
    "from smartprint import smartprint as sprint\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b1b1d6f-cee7-4b2f-81ca-7968f590f1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! rm -rf dist_plots\n",
    "# ! mkdir dist_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ba516a-ee88-45ca-a31c-a5e89c74e79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "london_45_days processed:  91%|█████████▏| 215/235 [00:00<00:00, 1996.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_date, end_date : 2020-02-01 2020-01-31\n",
      "\"Reached end of dates, skipping....Total #dates processed=\", len(dates) : Reached end of dates, skipping....Total #dates processed= 215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niskumar/NeurIPS2022-traffic4cast/train_data_all_cities/london-1-1-45-:   0%|          | 0/215 [00:00<?, ?it/s]\n",
      "computing distance to                                        random neighbours: 100%|██████████| 16559/16559 [00:03<00:00, 4901.59it/s]\n",
      "london_45_days processed:  91%|█████████▏| 215/235 [00:00<00:00, 14629.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_date, end_date : 2020-02-01 2020-01-31\n",
      "\"Reached end of dates, skipping....Total #dates processed=\", len(dates) : Reached end of dates, skipping....Total #dates processed= 215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niskumar/NeurIPS2022-traffic4cast/train_data_all_cities/london-1-1-45-:   0%|          | 0/215 [00:00<?, ?it/s]\n",
      "computing distance to                                        random neighbours: 100%|██████████| 16559/16559 [00:03<00:00, 4900.74it/s]\n",
      "london_45_days processed:  91%|█████████▏| 215/235 [00:00<00:00, 8276.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_date, end_date : 2020-02-01 2020-01-31\n",
      "\"Reached end of dates, skipping....Total #dates processed=\", len(dates) : Reached end of dates, skipping....Total #dates processed= 215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niskumar/NeurIPS2022-traffic4cast/train_data_all_cities/london-1-1-45-:   0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "#########################################################################\n",
    "#################  tryout: smoothing and thresholds  ####################\n",
    "#########################################################################\n",
    "# ! pip install peakdetect==1.2\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def compute_temp_dist(fileserial_num_list, L, plt):\n",
    "    random.shuffle(fileserial_num_list)\n",
    "        \n",
    "    distances = []\n",
    "    \n",
    "    data_cache = {}\n",
    "    sequential_delete = []\n",
    "    # sprint (int(np.random.rand() * N), len(fileserial_num_list))\n",
    "\n",
    "    # choose query point somewhere near the centre of the dataset\n",
    "    # so that we can compute distances on both sides (temporally)\n",
    "    query_index = np.inf\n",
    "    while (not 6000 < query_index < 8000):\n",
    "        n = int(np.random.rand() * len(fileserial_num_list))\n",
    "        query_point = np.load(fileserial_num_list[n])\n",
    "        query_index = int(fileserial_num_list[n].split(\"/\")[-1].split(\"_x.npy\")[0].split(\"-\")[-1])\n",
    "        # sprint (query_index)\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "    temporal_distances = []\n",
    "    # query_index = int(fileserial_num_list[n].split(\"/\")[-1].split(\"_x.npy\")[0].split(\"-\")[-1])\n",
    "\n",
    "    for i in tqdm(range(1, len(fileserial_num_list)), desc = \"computing distance to\\\n",
    "                                        random neighbours\"):\n",
    "        neighbour_x_array = np.load(fileserial_num_list[i])\n",
    "        \n",
    "        if \"_x.npy\" not in fileserial_num_list[i]:\n",
    "            raise Exception (\"Wrong file supplied; we should not have _y files\\n since we are looking for n-hood of x\")\n",
    "            \n",
    "        neighbour_index = int(fileserial_num_list[i].split(\"/\")[-1].split(\"_x.npy\")[0].split(\"-\")[-1])\n",
    "        \n",
    "        distances.append(np.max(np.abs(query_point - neighbour_x_array))) \n",
    "        temporal_distances.append((query_index - neighbour_index))\n",
    "\n",
    "        \n",
    "    # return temporal_distances, distances\n",
    "    temporal_distances, distances, indices = zip(*sorted(zip(temporal_distances, distances, list(range(1, len(fileserial_num_list))))))\n",
    "    # sprint (temporal_distances[:5])\n",
    "    # sprint ([fileserial_num_list[i] for i in indices][:5])\n",
    "    # sprint (distances[:16])\n",
    "    \n",
    "    nn = temporal_distances.index(0)\n",
    "\n",
    "    # plt.plot(temporal_distances[:96*7], np.convolve(distances[:96*7], [1/1]*1,\"same\"))\n",
    "    # plt.plot(temporal_distances[:64], np.convolve(distances[:64], [1/8]*8,\"same\"))\n",
    "    plt.plot(temporal_distances[nn - L : nn + L], distances[nn - L: nn + L], alpha=0.1)\n",
    "    \n",
    "    return distances[nn - L: nn + L], plt\n",
    "\n",
    "from peakdetect import peakdetect\n",
    "\n",
    "smooth_window = np.nan # no longer being used\n",
    "for L in [1000]:\n",
    "    for cityname in [\"london\"]:#, \"Madrid\", \"Melbourne\"]:\n",
    "        for scale in config.scales_def:\n",
    "            for i_o_length in [1]:\n",
    "                for pred_horiz in [1] :# list(range(1, 8)): # [1]:\n",
    "                    plotted_dist_list = []\n",
    "                    plt.clf()\n",
    "\n",
    "                    for run_n_times in range(10):\n",
    "                        ProcessRaw(cityname=cityname, i_o_length=i_o_length, prediction_horizon=pred_horiz, grid_size=scale)\n",
    "                        prefix = ProcessRaw.file_prefix(cityname, i_o_length, pred_horiz, scale)\n",
    "\n",
    "                        file_list = glob.glob(\"../train_data_all_cities/\" + prefix + \"/*_x.npy\")\n",
    "                        distances, plt = compute_temp_dist(file_list, L, plt)\n",
    "                        plotted_dist_list.append(distances)\n",
    "                    \n",
    "                    # plt.show()\n",
    "                    plt.clf()\n",
    "                    plt.title(\"Distance vs. temporal distance\\n\"+prefix)\n",
    "                    \n",
    "                    median_plot = np.median(np.array(plotted_dist_list), axis=0)\n",
    "                    plt.plot(np.arange(-L, L, 1), median_plot, label=\"Median plot\", alpha=0.5)\n",
    "                    # plt.plot(np.arange(-L, L, 1)[smooth_window//2:-smooth_window//2], \\\n",
    "                    #          np.convolve(np.median(np.array(plotted_dist_list), axis=0), \\\n",
    "                    #         [1/smooth_window]*smooth_window, \"same\")[smooth_window//2:-smooth_window//2]\\\n",
    "                    #          , label=\"Median plot-smooth\", alpha=1)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    plt.ylim(0, 6000)\n",
    "                    plt.xlabel(\"1 unit: 15 minutes\")\n",
    "                    plt.legend()\n",
    "                    plt.savefig(\"dist_plots/\"+prefix+\"-tempdist-\"+str(L)+\".png\")\n",
    "                    plt.clf()       \n",
    "                    \n",
    "\n",
    "                    # compute peaks\n",
    "                    peaks = peakdetect(median_plot, lookahead=50) \n",
    "                    higherPeaks = np.array(peaks[0])\n",
    "                    lowerPeaks = np.array(peaks[1])\n",
    "                    plt.plot(np.arange(-L, L, 1), median_plot)\n",
    "                    plt.plot(higherPeaks[:,0]-L, higherPeaks[:,1], 'ro')\n",
    "                    plt.plot(lowerPeaks[:,0]-L, lowerPeaks[:,1], 'ko')\n",
    "                    plt.xticks(np.arange(-10, 10) * 96, [\"day_\"+str(x) for x in range(-10,10)],rotation=90)\n",
    "                    plt.title(\"Distance vs. temporal distance\\n\"+prefix+\"-zoom1\")\n",
    "                    plt.savefig(\"dist_plots/\"+\"Distance vs. temporal distance\\n\"+prefix+\"-zoom1\"+\".png\")\n",
    "                    plt.clf()\n",
    "\n",
    "\n",
    "                    peaks = peakdetect(median_plot, lookahead=50) \n",
    "                    higherPeaks = np.array(peaks[0])\n",
    "                    lowerPeaks = np.array(peaks[1])\n",
    "                    plt.plot(np.arange(-L, L, 1), median_plot)\n",
    "                    plt.plot(higherPeaks[:,0]-L, higherPeaks[:,1], 'ro')\n",
    "                    plt.plot(lowerPeaks[:,0]-L, lowerPeaks[:,1], 'ko')\n",
    "                    plt.xticks(np.arange(-10, 10) * 96, [\"day_\"+str(x) for x in range(-10,10)],rotation=90)\n",
    "                    plt.xlim(-200, 200)\n",
    "                    plt.title(\"Distance vs. temporal distance\\n\"+prefix +\"-zoom2\")\n",
    "                    plt.savefig(\"dist_plots/\"+\"Distance vs. temporal distance\\n\"+prefix +\"-zoom2\" + \".png\")                    \n",
    "                    plt.clf()\n",
    "\n",
    "\n",
    "                    peaks = peakdetect(median_plot, lookahead=50) \n",
    "                    higherPeaks = np.array(peaks[0])\n",
    "                    lowerPeaks = np.array(peaks[1])\n",
    "                    plt.plot(np.arange(-L, L, 1), median_plot)\n",
    "                    plt.plot(higherPeaks[:,0]-L, higherPeaks[:,1], 'ro')\n",
    "                    plt.plot(lowerPeaks[:,0]-L, lowerPeaks[:,1], 'ko')\n",
    "                    plt.xticks(np.arange(-20, 20) * 4, [\"hour_\"+str(x) for x in range(-20,20)],rotation=90)\n",
    "                    plt.xlim(-96, 96)\n",
    "                    plt.title(\"Distance vs. temporal distance\\n\"+prefix+ \"-zoom3\")\n",
    "                    plt.savefig(\"dist_plots/\"+\"Distance vs. temporal distance\\n\"+prefix+ \"-zoom3\"+\".png\")                    \n",
    "                    plt.clf()\n",
    "\n",
    "\n",
    "                    where_min = np.argmin(lowerPeaks[:,1])\n",
    "                    x1 = lowerPeaks[where_min-1, 0]\n",
    "                    x2 = lowerPeaks[where_min+1, 0]\n",
    "                    y1 = lowerPeaks[where_min-1, 1]\n",
    "                    y2 = lowerPeaks[where_min+1, 1]\n",
    "\n",
    "                    # reduce a small value to avoid the immediate next step (noise)\n",
    "                    thresh = min(y1, y2) - 5\n",
    "\n",
    "                    plt.plot(np.arange(-L, L, 1), [thresh] * (2 * L), label=\"threshold\")\n",
    "\n",
    "                    peaks = peakdetect(median_plot, lookahead=50) \n",
    "                    higherPeaks = np.array(peaks[0])\n",
    "                    lowerPeaks = np.array(peaks[1])\n",
    "\n",
    "                    plt.scatter([x1-L, x2-L], [y1, y2], color='b', marker='*', alpha=0.5, s=300)\n",
    "                    plt.plot(np.arange(-L, L, 1), median_plot, label=\"median_plot\")\n",
    "                    plt.plot(higherPeaks[:,0]-L, higherPeaks[:,1], 'ro')\n",
    "                    plt.plot(lowerPeaks[:,0]-L, lowerPeaks[:,1], 'ko')\n",
    "                    plt.xticks(np.arange(-20, 20) * 4, [\"hour_\"+str(x) for x in range(-20,20)],rotation=90)\n",
    "                    plt.xlim(-96, 96)\n",
    "\n",
    "\n",
    "                    x_vals_for_below_thresh = np.argwhere(np.diff(np.sign(median_plot - thresh))).flatten()\n",
    "                    left = x_vals_for_below_thresh.min() - L\n",
    "                    bottom = 0\n",
    "                    width = x_vals_for_below_thresh.max() - x_vals_for_below_thresh.min()\n",
    "                    height = thresh\n",
    "\n",
    "                    rect = patches.Rectangle((left, bottom), width, height, linewidth=1, edgecolor='r', facecolor='gray', alpha=0.3)\n",
    "                    # rect = patches.Rectangle((50, 100), 40, 30, linewidth=1, edgecolor='r', facecolor='none')\n",
    "                    ax = plt.gca()\n",
    "                    # Add the patch to the Axes\n",
    "                    ax.add_patch(rect)\n",
    "                    plt.legend()\n",
    "                    plt.title(\"Distance vs. temporal distance\\n\"+prefix+ \"-zoom3\" + \" \\n#datapoints=\"+str(width), fontsize=8)\n",
    "                    plt.savefig(\"dist_plots/\"+\"Distance vs. temporal distance\\n\"+prefix+ \"-zoom3\" + \" \\n#datapoints=\"+str(width)+\".png\")\n",
    "                    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d425d98-d357-4ba9-82ae-5a2ffb42cdaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d618a8d6-853a-4eaa-bff4-52f3ed8b2810",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64b43de5-a9fa-4668-9a42-94f97dc80999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../train_data_all_cities/london-1-1-45-/london-1-1-45-13346_x.npy',\n",
       " '../train_data_all_cities/london-1-1-45-/london-1-1-45-12426_x.npy',\n",
       " '../train_data_all_cities/london-1-1-45-/london-1-1-45-13023_x.npy',\n",
       " '../train_data_all_cities/london-1-1-45-/london-1-1-45-15303_x.npy',\n",
       " '../train_data_all_cities/london-1-1-45-/london-1-1-45-7305_x.npy',\n",
       " '../train_data_all_cities/london-1-1-45-/london-1-1-45-2012_x.npy',\n",
       " '../train_data_all_cities/london-1-1-45-/london-1-1-45-4537_x.npy',\n",
       " '../train_data_all_cities/london-1-1-45-/london-1-1-45-3832_x.npy',\n",
       " '../train_data_all_cities/london-1-1-45-/london-1-1-45-1589_x.npy',\n",
       " '../train_data_all_cities/london-1-1-45-/london-1-1-45-14047_x.npy',\n",
       " '../train_data_all_cities/london-1-1-45-/london-1-1-45-506_x.npy']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7f27048-aa6c-482e-97c9-03c02156dc19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../train_data_all_cities/london-1-1-45-/london-1-1-45-787_x.npy',\n",
       " '../train_data_all_cities/london-1-1-45-/london-1-1-45-134_x.npy',\n",
       " '../train_data_all_cities/london-1-1-45-/london-1-1-45-14457_x.npy',\n",
       " '../train_data_all_cities/london-1-1-45-/london-1-1-45-15048_x.npy',\n",
       " '../train_data_all_cities/london-1-1-45-/london-1-1-45-9595_x.npy']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00748bfc-1a00-4fab-9b57-47080b8b5b74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "459e4a8e-a033-4638-9d5a-0d5bbdf1b621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/niskumar/NeurIPS2022-traffic4cast/exploration\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c48ab22-4151-4bdb-9a93-0078353c08c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942ee717-3f80-4e1b-9155-84228ee7f716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64808141-55b5-417a-95f1-e43bb5c8a686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d11167c-f9ab-4da6-99c0-4fea86039d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140080bc-1265-4835-a655-a97a7a9f3644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b727e2-b398-4ea1-b13b-10341496fce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9c5c01-9a37-4772-bb3e-45e7924c004e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd8d3cf-5001-454a-b204-91663df0befc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
